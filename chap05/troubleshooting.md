# ğŸ™ï¸ ì˜¤ë””ì˜¤ í…ìŠ¤íŠ¸ ë³€í™˜ í”„ë¡œì íŠ¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”
Whisper ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ë¡œì»¬ í™˜ê²½ì—ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í”„ë¡œì íŠ¸ ì§„í–‰ ì¤‘ ë°œìƒí•œ ì£¼ìš” ì´ìŠˆ ë° í•´ê²° ë°©ë²• ì •ë¦¬.

---

## ğŸ”´ ë°œìƒí•œ ì£¼ìš” ë¬¸ì œë“¤

### 1ï¸âƒ£ **FFmpeg ê²½ë¡œ ì„¤ì • ë¯¸ë°˜ì˜**

#### âŒ ë¬¸ì œ ìƒí™©
```
ValueError: ffmpeg was not found but is required to load audio files from filename
```

#### ğŸ” ì›ì¸ ë¶„ì„
- `os.environ["PATH"]`ë¡œ FFmpeg ê²½ë¡œë¥¼ ì„¤ì •í–ˆìœ¼ë‚˜ Python í”„ë¡œì„¸ìŠ¤ê°€ ì¸ì‹í•˜ì§€ ëª»í•¨
- ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ ë‹¤ì‹œ ì½ì§€ ì•ŠìŒ
- FFmpeg ì„¤ì •ì´ ì´ë£¨ì–´ì§€ê¸° **ì „ì—** ëª¨ë¸ ë¡œë“œ ì½”ë“œê°€ ì‹¤í–‰ë¨

#### âœ… í•´ê²° ë°©ë²•

**Step 1: ë³„ë„ì˜ ì…€ì—ì„œ ë¨¼ì € ì‹¤í–‰**
```python
import os

# FFmpeg ê²½ë¡œë¥¼ ë¨¼ì € ì„¤ì • (ëŒ€ë¬¸ì PATH ì£¼ì˜!)
os.environ["PATH"] += os.pathsep + r"C:\Users\hoyon\OneDrive\ë°”íƒ• í™”ë©´\ê°œë°œê³µë¶€\LLMì„í™œìš©í•œAIì—ì´ì „íŠ¸\chap05\ffmpeg-2025-12-07-git-c4d22f2d2c-full_build\bin"

print("âœ“ FFmpeg ê²½ë¡œ ì„¤ì • ì™„ë£Œ")
```

**Step 2: ê·¸ ë‹¤ìŒ ì…€ì—ì„œ ëª¨ë¸ ë¡œë“œ**
```python
import torch
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline

device = "cpu"  # ë˜ëŠ” "cuda:0" if torch.cuda.is_available()
torch_dtype = torch.float32  # ë˜ëŠ” torch.float16 (GPU ì‚¬ìš© ì‹œ)

model_id = "openai/whisper-large-v3-turbo"

model = AutoModelForSpeechSeq2Seq.from_pretrained(
    model_id, 
    torch_dtype=torch_dtype, 
    low_cpu_mem_usage=True, 
    use_safetensors=True
)
model.to(device)

processor = AutoProcessor.from_pretrained(model_id)

pipe = pipeline(
    "automatic-speech-recognition",
    model=model,
    tokenizer=processor.tokenizer,
    feature_extractor=processor.feature_extractor,
    torch_dtype=torch_dtype,
    device=device,
    return_timestamps=True,
    chunk_length_s=10,
    stride_length_s=2,
)

print("âœ“ ëª¨ë¸ ë° íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì™„ë£Œ")
```

#### ğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸
- **`PATH`ëŠ” ëŒ€ë¬¸ì** (ì†Œë¬¸ì "path" ì‚¬ìš© ì‹œ ì¸ì‹ ì•ˆ ë¨)
- **ë°˜ë“œì‹œ ëª¨ë¸ ë¡œë“œ ì „ì— ì„¤ì •**
- **ì…€ ìˆœì„œê°€ ì¤‘ìš”í•¨** (FFmpeg ì„¤ì • ì…€ â†’ ëª¨ë¸ ë¡œë“œ ì…€)

---

### 2ï¸âƒ£ **CUDA ë²„ì „ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹¤íŒ¨**

#### âŒ ë¬¸ì œ ìƒí™©
```
âœ“ torch ë²„ì „: 2.9.1+cpu  # CPU ë²„ì „ìœ¼ë¡œ ì„¤ì¹˜ë¨
âœ“ CUDA ì‚¬ìš© ê°€ëŠ¥: False
```

#### ğŸ” ì›ì¸ ë¶„ì„
- PyTorchë¥¼ ê¸°ë³¸ ì„¤ì¹˜ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ë©´ CPU ë²„ì „ë§Œ ì„¤ì¹˜ë¨
- GPUë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ CUDA ì§€ì› ë²„ì „ì„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•´ì•¼ í•¨
- ì˜ëª»ëœ pip ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ë©´ í˜¸í™˜ì„± ë¬¸ì œ ë°œìƒ

#### âœ… í•´ê²° ë°©ë²•

**GPU ìˆëŠ” ê²½ìš°:**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
```

**GPU ì—†ëŠ” ê²½ìš°:**
```bash
pip install torch torchvision torchaudio
```

#### ğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸
- GPU ì—†ìœ¼ë©´ ë¬´ë¦¬í•´ì„œ CUDA ì„¤ì¹˜í•  í•„ìš” ì—†ìŒ (CPUë¡œë„ ì¶©ë¶„)
- Jupyter ë…¸íŠ¸ë¶ í™˜ê²½ì€ ì£¼ë¡œ CPU ì‚¬ìš©
- ì„¤ì¹˜ í›„ **ë°˜ë“œì‹œ ì»¤ë„ ì¬ì‹œì‘** í•„ìš”

---

### 3ï¸âƒ£ **Torchì™€ Torchvision ë²„ì „ ë¶ˆì¼ì¹˜**

#### âŒ ë¬¸ì œ ìƒí™©
```
RuntimeError: operator torchvision::nms does not exist
```

#### ğŸ” ì›ì¸ ë¶„ì„
- torchì™€ torchvisionì˜ ë¹Œë“œ ë²„ì „ì´ í˜¸í™˜ë˜ì§€ ì•ŠìŒ
- torchëŠ” CPU ë²„ì „, torchvisionì€ CUDA ë²„ì „ ë“± ì„ì—¬ ì„¤ì¹˜ë¨
- ê¸°ì¡´ ìºì‹œ íŒŒì¼ì´ ë‚¨ì•„ìˆì–´ ë²„ì „ ì¶©ëŒ ë°œìƒ

#### âœ… í•´ê²° ë°©ë²•

**Step 1: ëª¨ë“  torch ê´€ë ¨ íŒ¨í‚¤ì§€ ì œê±°**
```bash
pip uninstall -y torch torchvision torchaudio
pip cache purge
```

**Step 2: ì˜¬ë°”ë¥¸ ë²„ì „ìœ¼ë¡œ ì¬ì„¤ì¹˜**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
```

**Step 3: Jupyter ì»¤ë„ ì¬ì‹œì‘**
```
Kernel â†’ Restart Kernel and Clear All Outputs
```

#### ğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸
- ì™„ì „ ì œê±° í›„ ì¬ì„¤ì¹˜ê°€ í•„ìˆ˜
- ìºì‹œ ì œê±° ì¤‘ìš”
- ë²„ì „ í˜¸í™˜ì„±ì€ í•­ìƒ í™•ì¸ í•„ìš”

---

### 4ï¸âƒ£ **transformers ëª¨ë“ˆ import ì˜¤ë¥˜**

#### âŒ ë¬¸ì œ ìƒí™©
```
ModuleNotFoundError: Could not import module 'AutoProcessor'
ImportError: cannot import name 'add_model_info_to_auto_map'
```

#### ğŸ” ì›ì¸ ë¶„ì„
- transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‚´ë¶€ ëª¨ë“ˆë“¤ì˜ ë²„ì „ ë¶ˆì¼ì¹˜
- ì´ì „ ë²„ì „ì˜ ìºì‹œ íŒŒì¼ì´ ë‚¨ì•„ìˆìŒ
- íŒ¨í‚¤ì§€ ë²„ì „ì´ ëª…ì‹œë˜ì§€ ì•Šì•„ í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ë²„ì „ì´ ì„¤ì¹˜ë¨

#### âœ… í•´ê²° ë°©ë²•

**Step 1: transformers ìºì‹œ ì œê±° ë° ì—…ê·¸ë ˆì´ë“œ**
```bash
pip uninstall -y transformers
pip cache purge
pip install --upgrade transformers
```

**Step 2: Jupyter ì»¤ë„ ì¬ì‹œì‘**
```
Kernel â†’ Restart Kernel and Clear All Outputs
```

#### ğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸
- ë²„ì „ ëª…ì‹œ ì—†ìœ¼ë©´ ìµœì‹  ì•ˆì • ë²„ì „ ì„¤ì¹˜ ê¶Œì¥
- ë¼ì´ë¸ŒëŸ¬ë¦¬ ë‚´ë¶€ ë¶ˆì¼ì¹˜ëŠ” ì™„ì „ ì œê±° í›„ ì¬ì„¤ì¹˜ë¡œ í•´ê²°
- ì£¼ê¸°ì ì¸ ì»¤ë„ ì¬ì‹œì‘ í•„ìˆ˜

---

## ğŸ“ CUDA ê°œë… ì •ë¦¬

### CUDAë€?
- **CUDA** = Compute Unified Device Architecture
- NVIDIA GPUë¥¼ í™œìš©í•˜ì—¬ ë³‘ë ¬ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ê¸°ìˆ 
- GPUë¥¼ ì‚¬ìš©í•˜ë©´ CPUë³´ë‹¤ í›¨ì”¬ ë¹ ë¥¸ ì—°ì‚° ê°€ëŠ¥

### ë‹¹ì‹ ì˜ ìƒí™©
```
Jupyter ë…¸íŠ¸ë¶ í™˜ê²½ â†’ GPU ì—†ìŒ â†’ CUDA ë¶ˆí•„ìš”
â†“
CPUë¡œ ì¶©ë¶„íˆ ì‘ë™ ê°€ëŠ¥
```

### í™•ì¸ ë°©ë²•
```python
import torch
print(torch.cuda.is_available())  # False = GPU ì—†ìŒ, True = GPU ìˆìŒ
```

### CUDA ê´€ë ¨ ì„¤ì •
```python
# GPU ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ CPU ì‚¬ìš©
device = "cuda:0" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

# float16ì€ GPU ì—°ì‚° ìµœì í™”, float32ëŠ” CPU í‘œì¤€
```

---

## ğŸ“¦ ìµœì¢… ì„¤ì • ê°€ì´ë“œ

### ê¶Œì¥ ì„¤ì¹˜ ìˆœì„œ

#### 1ë‹¨ê³„: ê¸°ë³¸ íŒ¨í‚¤ì§€
```bash
pip install --upgrade pip
pip install transformers datasets[audio] accelerate
```

#### 2ë‹¨ê³„: PyTorch (CPU ë²„ì „ ê¶Œì¥)
```bash
pip install torch torchvision torchaudio
```

#### 3ë‹¨ê³„: ì˜¤ë””ì˜¤ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
```bash
pip install librosa soundfile
```

#### 4ë‹¨ê³„: Jupyter ë„êµ¬
```bash
pip install jupyter ipywidgets
```

### Jupyter ë…¸íŠ¸ë¶ ìµœì  êµ¬ì¡°

```python
# [ì…€ 1] íŒ¨í‚¤ì§€ ì„í¬íŠ¸
import os
import torch
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline

# [ì…€ 2] FFmpeg ê²½ë¡œ ì„¤ì • (ë°˜ë“œì‹œ ë¨¼ì €!)
os.environ["PATH"] += os.pathsep + r"C:\Users\...\ffmpeg\bin"

# [ì…€ 3] ëª¨ë¸ ë¡œë“œ
device = "cpu"
model_id = "openai/whisper-large-v3-turbo"
model = AutoModelForSpeechSeq2Seq.from_pretrained(...)
processor = AutoProcessor.from_pretrained(model_id)
pipe = pipeline(...)

# [ì…€ 4] ì˜¤ë””ì˜¤ ì²˜ë¦¬
result = pipe("./audio/file.mp3")
print(result["text"])
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

í”„ë¡œì íŠ¸ ì‹œì‘ ì „ ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:

- [ ] FFmpeg ì„¤ì¹˜ ë° ê²½ë¡œ í™•ì¸
- [ ] íŒ¨í‚¤ì§€ ì„¤ì¹˜ ìˆœì„œ ì¤€ìˆ˜ (transformers â†’ torch â†’ librosa)
- [ ] Jupyter ì»¤ë„ ì¬ì‹œì‘ ì™„ë£Œ
- [ ] `torch.cuda.is_available()` í™•ì¸ (Falseì—¬ë„ ì •ìƒ)
- [ ] FFmpeg ê²½ë¡œ ì„¤ì • ì½”ë“œê°€ ëª¨ë¸ ë¡œë“œ ì „ì— ì‹¤í–‰ë¨
- [ ] ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì •í™•ì„± í™•ì¸

---

## ğŸš€ ë¹ ë¥¸ í•´ê²° í”Œë¡œìš°

### ë¬¸ì œ: "ffmpeg was not found"
```
â†’ Step 1: os.environ["PATH"] ì½”ë“œ ì‹¤í–‰
â†’ Step 2: ëª¨ë¸ ë¡œë“œ ì½”ë“œ ì‹¤í–‰
```

### ë¬¸ì œ: "CUDA ê´€ë ¨ ì˜¤ë¥˜"
```
â†’ Step 1: CUDA ì„¤ì¹˜ ë¶ˆí•„ìš” (GPU ì—†ìœ¼ë©´)
â†’ Step 2: CPU ë²„ì „ìœ¼ë¡œ ì„¤ì¹˜ í›„ ì§„í–‰
```

### ë¬¸ì œ: "import ì˜¤ë¥˜"
```
â†’ Step 1: pip uninstall -y [íŒ¨í‚¤ì§€ëª…]
â†’ Step 2: pip cache purge
â†’ Step 3: pip install [íŒ¨í‚¤ì§€ëª…]
â†’ Step 4: Kernel â†’ Restart
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/)
- [Transformers ì„¤ì¹˜ ê°€ì´ë“œ](https://huggingface.co/docs/transformers/installation)
- [Jupyter Notebook ì»¤ë„ ë¬¸ì œ í•´ê²°](https://jupyter.readthedocs.io/en/latest/)

---

